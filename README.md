# RAG Chatbot Backend Documentation (Django)

## Overview

This backend powers a Retrieval-Augmented Generation (RAG) chatbot intended for the QC government. It allows users to interact with a chatbot that retrieves relevant government documents (particularly ordinances and resolutions) and provides contextual answers. It also supports document upload and indexing via Textract.

---

## Technology Stack

* **Framework:** Django, Django REST Framework
* **Vector Store:** Weaviate
* **OCR & Layout Parsing:** AWS Textract (asynchronous via S3)
* **Language Model:** OpenAI API
* **Frontend:** Streamlit chatbot interface for trial/testing

---

## API Endpoints

### 1. `POST /api/chat/` — **Chat with RAG Agent**

Processes user input and returns a generated response.

#### Request Body

```json
{
  "message": "What criteria must a resident of Quezon City meet to qualify for the Betty Go-Belmonte Research Grants Program?",
  "history": [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Hi! How can I help you today?"}
  ]
}
```

#### Response

```json
{
  "answer": "To qualify for the Betty Go-Belmonte Research Grants Program, a resident of Quezon City must meet the following criteria ... ",
  "sources": [
    "SP-3174, S-2023"
  ]
}
```

#### Key Modules:

* `RetrievalDecisionModule`: Classifies if document retrieval is needed.
* `QueryTransformationModule`: Refines or reformulates queries.
* `DocumentRetrievalModule`: Interfaces with Weaviate to fetch relevant documents.
* `ResponseGeneratorModule`: Uses LLM to generate answers.
* `AnswerValidationAgent`: Verifies the validity of generated answers.

#### Chat History Format

The frontend (e.g., Streamlit) should maintain a list of message objects that is passed to the backend as the `history` field. Each message must include:

```json
{
  "role": "user"
  "content": "..."
}
```
or

```json
{
  "role": "assistant",
  "content": "..."
}
```

* `"role": "user"` indicates a message written by the end-user—typically a query, question, or statement.
* `"role": "assistant"` indicates a message generated by the chatbot based on document retrieval and language model reasoning.
* `"content"` holds the actual message text:

  * For `user`, this is the **user's query or instruction**.
  * For `assistant`, this is the **generated response**, which **may include both the direct answer and cited document identifiers or excerpts used to form the response**.

**Important:**
The frontend **must only send** the `role` and `content` keys for each message. **Do not include frontend-specific keys** such as `sources`, `query`, or other metadata, as these are not required or handled by the backend and may cause issues.

##### Example (Python/Streamlit):

```python
history = [
  {"role": m["role"], "content": m["content"]}
  for m in st.session_state.messages
]
response = requests.post(
    'http://127.0.0.1:8000/api/chat/',
    json={"message": user_input, "history": history}
)
```

The backend will internally limit the context to the most recent six messages.

---

### 2. `POST /api/upload/` — **Upload and Index New PDFs**

Uploads, extracts, summarizes, and indexes government PDFs into Weaviate for future retrieval.

#### Form Data

* `file`: Multiple `.pdf` files

#### Sample Input

* `SP-3174, S-2023.pdf`

#### Response (multi-status)

```json
{
  "results": [
    {
      "file": "SP-3174, S-2023.pdf",
      "status": "success",
      "message": "Uploaded and processed successfully.",
      "source": "SP-3174, S-2023"
    },
    {
      "file": "Invalid_File.docx",
      "status": "failed",
      "message": "Only PDF files are supported."
    }
  ]
}
```

#### Workflow:

1. Checks for duplicate files.
2. Saves the PDF in `New Documents/`.
3. Uploads files to S3 and initiates asynchronous AWS Textract jobs.
4. Extracts text and layout structure from Textract results.
5. Indexes the summarized documents to Weaviate.

---

### 3. `GET /api/check/` — **Health Check**

Simple endpoint to check if the server is up and running.

#### Response

```json
{
  "status": "Server is running"
}
```

---

## Directory Overview

```bash
Capstone-Project/
├── chatapp/
│   ├── views.py
│   ├── textract.py               # For document indexing
│   ├── chat_agent.py             # RAG modules
├── evaluations/                  # Test datasets and evaluations performed
├── embeddings/                   # Local embedding model directory (downloaded when download_embedding.py is run)
├── requirements.txt              # Packages needed to run the project
├── docker-compose.yaml           
└── manage.py
```

---

## Setup Instructions

1. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

2. **Download Embedding Model:**

   Run the following script to download the embedding model required for vectorization during document indexing and chat retrieval:

   ```bash
   python download_embedding.py
   ```

    This will automatically download the embedding model (e.g., `BAAI/bge-small-en`) and save it in the `embedding/` directory.

3. **Restore initial Weaviate database (optional but recommended):**

   If you have an initial Weaviate volume archive (`weaviate-db.tar.gz`), extract it **before** running Docker:

   ```bash
   mkdir -p ./weaviate
   tar -xzf weaviate-db.tar.gz -C ./weaviate
   ```

   This ensures your Weaviate container boots with preloaded documents and metadata.

4. **Start Weaviate locally:**

   ```bash
   docker-compose up -d
   ```

5. **Run Django server:**

   ```bash
   python manage.py runserver
   ```

---

## Deployment Notes

* This backend is intended to be **deployed internally or behind a secure gateway** for QC government staff.
* We recommend hosting it behind **NGINX with HTTPS**, and enforcing **authentication** for production use.
* Ensure AWS Textract has access to necessary IAM credentials and S3 permissions for asynchronous processing.

  * If deploying to an **EC2 instance**, configure appropriate **IAM role permissions**.
  * If using another environment, ensure `.env` contains **AWS\_ACCESS\_KEY\_ID** and **AWS\_SECRET\_ACCESS\_KEY**.

### Example `.env` File

```env
OPENAI_API_KEY=sk-...
AWS_ACCESS_KEY_ID=...
AWS_SECRET_ACCESS_KEY=...
AWS_REGION=...
S3_BUCKET_NAME=...
```

---

## Frontend Integration

A companion **Streamlit frontend** is provided for demonstration and testing. It supports:

* Batch PDF upload (calls `/api/upload/`)
* Conversational chat UI (calls `/api/chat/` with tracked history)
* Maintains history using `st.session_state`

The frontend serves as a testing tool and should be adjusted or secured for production use.
