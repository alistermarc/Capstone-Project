[1mdiff --git a/.gitignore b/.gitignore[m
[1mindex 80c9a7c..dfccf3e 100644[m
[1m--- a/.gitignore[m
[1m+++ b/.gitignore[m
[36m@@ -34,5 +34,4 @@[m [mweaviate_data/[m
 weaviate/[m
 .streamlit.py.swp[m
 weavaiate-db.tar.gz[m
[31m-[m
[31m-[m
[32m+[m[32mcapstone_venv/[m
[1mdiff --git a/Dockerfile b/Dockerfile[m
[1mnew file mode 100644[m
[1mindex 0000000..ab91a93[m
[1m--- /dev/null[m
[1m+++ b/Dockerfile[m
[36m@@ -0,0 +1,15 @@[m
[32m+[m[32mFROM python@sha256:9c85d1d49df54abca1c5db3b4016400e198e9e9bb699f32f1ef8e5c0c2149ccf[m
[32m+[m
[32m+[m[32mWORKDIR /app[m
[32m+[m
[32m+[m[32mCOPY . .[m
[32m+[m
[32m+[m[32mRUN apt-get update && apt-get install -y gcc[m
[32m+[m[32mRUN pip install --upgrade pip==25.1.1[m
[32m+[m[32mRUN pip install --no-cache -r requirements.txt[m
[32m+[m[32mRUN pip install https://download.pytorch.org/whl/cpu/torch-2.1.1%2Bcpu-cp311-cp311-linux_x86_64.whl[m
[32m+[m[32m# RUN pip install https://download.pytorch.org/whl/cpu/torch-2.1.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl[m
[32m+[m
[32m+[m[32mRUN python3 generate.py[m
[32m+[m
[32m+[m[32mCMD ["python3.11", "manage.py", "runserver", "0.0.0.0:8000"][m
\ No newline at end of file[m
[1mdiff --git a/chat_backend/settings.py b/chat_backend/settings.py[m
[1mindex bebd452..8e29288 100644[m
[1m--- a/chat_backend/settings.py[m
[1m+++ b/chat_backend/settings.py[m
[36m@@ -31,7 +31,7 @@[m [mSECRET_KEY = 'django-insecure-59d!_quk-h0+m#wgr61(cl$&_0v9kyl60th-1%4j4g98igdcjc[m
 # SECURITY WARNING: don't run with debug turned on in production![m
 DEBUG = True[m
 [m
[31m-ALLOWED_HOSTS = ['202.92.129.237', 'localhost', '127.0.0.1', '3.106.232.198'][m
[32m+[m[32mALLOWED_HOSTS = ['202.92.129.237', 'localhost', '127.0.0.1', 'chat-django'][m
 [m
 [m
 # Application definition[m
[1mdiff --git a/chatapp/chat_agent.py b/chatapp/chat_agent.py[m
[1mindex e9cbdba..58acf89 100644[m
[1m--- a/chatapp/chat_agent.py[m
[1m+++ b/chatapp/chat_agent.py[m
[36m@@ -130,7 +130,7 @@[m [mclass QueryTransformationModule:[m
 [m
 [m
 class DocumentRetrievalModule(AbstractContextManager):[m
[31m-    def __init__(self, host="localhost", collection_name="BAAI", alpha=0.5, context_window=1):[m
[32m+[m[32m    def __init__(self, host="weaviate", collection_name="BAAI", alpha=0.5, context_window=1):[m
         self.host = host[m
         self.collection_name = collection_name[m
         self.alpha = alpha[m
[1mdiff --git a/chatapp/views.py b/chatapp/views.py[m
[1mindex 8a6072b..c479b64 100644[m
[1m--- a/chatapp/views.py[m
[1m+++ b/chatapp/views.py[m
[36m@@ -36,7 +36,7 @@[m [mclass ChatAPIView(APIView):[m
         else:[m
             refined_query = query_transformation_module.refine_query_with_history(user_input, context_str)[m
 [m
[31m-            with DocumentRetrievalModule(host="localhost", collection_name="BAAI", alpha=0.5) as searcher:[m
[32m+[m[32m            with DocumentRetrievalModule(host="weaviate", collection_name="BAAI", alpha=0.5) as searcher:[m
                 agent = AnswerValidationAgent()[m
                 while agent.current_attempt < agent.max_attempts:[m
                     if agent.current_attempt > 0:[m
[1mdiff --git a/docker-compose.yaml b/docker-compose.yaml[m
[1mindex d58ef53..d1326fc 100644[m
[1m--- a/docker-compose.yaml[m
[1m+++ b/docker-compose.yaml[m
[36m@@ -1,17 +1,24 @@[m
[31m----[m
 services:[m
[32m+[m
[32m+[m[32m  chat-streamlit:[m
[32m+[m[32m    image: chat-streamlit:latest[m
[32m+[m[32m    container_name: chat-streamlit[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "8501:8501"[m
[32m+[m[32m    restart: on-failure[m
[32m+[m
   weaviate:[m
     command:[m
[31m-    - --host[m
[31m-    - 0.0.0.0[m
[31m-    - --port[m
[31m-    - '8080'[m
[31m-    - --scheme[m
[31m-    - http[m
[32m+[m[32m      - --host[m
[32m+[m[32m      - 0.0.0.0[m
[32m+[m[32m      - --port[m
[32m+[m[32m      - '8080'[m
[32m+[m[32m      - --scheme[m
[32m+[m[32m      - http[m
     image: cr.weaviate.io/semitechnologies/weaviate:1.30.1[m
     ports:[m
[31m-    - 8080:8080[m
[31m-    - 50051:50051[m
[32m+[m[32m      - 8080:8080[m
[32m+[m[32m      - 50051:50051[m
     volumes:[m
       - ./weaviate:/var/lib/weaviate[m
     restart: on-failure:0[m
[36m@@ -21,7 +28,14 @@[m [mservices:[m
       PERSISTENCE_DATA_PATH: '/var/lib/weaviate'[m
       ENABLE_API_BASED_MODULES: 'true'[m
       CLUSTER_HOSTNAME: 'node1'[m
[31m-volumes:[m
[31m-  weaviate_data:[m
[31m-...[m
[31m- [m
[32m+[m
[32m+[m[32m  chat-django:[m
[32m+[m[32m    image: chat-django:latest[m
[32m+[m[32m    container_name: chat-django[m
[32m+[m[32m    ports:[m
[32m+[m[32m      - "8000:8000"[m
[32m+[m[32m    restart: on-failure[m
[32m+[m[32m    env_file:[m
[32m+[m[32m      - .env[m
[32m+[m[32m    depends_on:[m
[32m+[m[32m      - weaviate[m
[1mdiff --git a/download_embedding.py b/download_embedding.py[m
[1mnew file mode 100644[m
[1mindex 0000000..4c771be[m
[1m--- /dev/null[m
[1m+++ b/download_embedding.py[m
[36m@@ -0,0 +1,8 @@[m
[32m+[m[32mfrom transformers import AutoTokenizer, AutoModel[m
[32m+[m
[32m+[m[32mtokenizer = AutoTokenizer.from_pretrained("BAAI/bge-base-en-v1.5")[m
[32m+[m[32mmodel = AutoModel.from_pretrained("BAAI/bge-base-en-v1.5")[m
[32m+[m
[32m+[m[32msave_path = "./embeddings"[m
[32m+[m[32mtokenizer.save_pretrained(save_path)[m
[32m+[m[32mmodel.save_pretrained(save_path)[m
\ No newline at end of file[m
[1mdiff --git a/frontend/Dockerfile b/frontend/Dockerfile[m
[1mnew file mode 100644[m
[1mindex 0000000..e767071[m
[1m--- /dev/null[m
[1m+++ b/frontend/Dockerfile[m
[36m@@ -0,0 +1,10 @@[m
[32m+[m[32mFROM python@sha256:9c85d1d49df54abca1c5db3b4016400e198e9e9bb699f32f1ef8e5c0c2149ccf[m
[32m+[m
[32m+[m[32mWORKDIR /app[m
[32m+[m
[32m+[m[32mCOPY . .[m
[32m+[m
[32m+[m[32mRUN pip install --upgrade pip==25.1.1[m
[32m+[m[32mRUN pip install --no-cache -r requirements.txt[m
[32m+[m
[32m+[m[32mCMD ["streamlit", "run", "streamlit.py", "--server.port=8501"][m
\ No newline at end of file[m
[1mdiff --git a/frontend/requirements.txt b/frontend/requirements.txt[m
[1mnew file mode 100644[m
[1mindex 0000000..1e3d8d0[m
[1m--- /dev/null[m
[1m+++ b/frontend/requirements.txt[m
[36m@@ -0,0 +1 @@[m
[32m+[m[32mstreamlit==1.45.1[m
[1mdiff --git a/streamlit.py b/frontend/streamlit.py[m
[1msimilarity index 89%[m
[1mrename from streamlit.py[m
[1mrename to frontend/streamlit.py[m
[1mindex 2a52ac9..138f499 100644[m
[1m--- a/streamlit.py[m
[1m+++ b/frontend/streamlit.py[m
[36m@@ -1,6 +1,8 @@[m
 import streamlit as st[m
 import requests[m
 [m
[32m+[m[32mbackend_url = "chat-django"[m
[32m+[m
 # Initialize single chat session[m
 if "messages" not in st.session_state:[m
     st.session_state.messages = [][m
[36m@@ -27,7 +29,7 @@[m [mwith st.sidebar:[m
 [m
         try:[m
             upload_response = requests.post([m
[31m-                "http://127.0.0.1:8000/api/upload/",[m
[32m+[m[32m                f"http://{backend_url}:8000/api/upload/",[m
                 files=files[m
             )[m
 [m
[36m@@ -68,10 +70,16 @@[m [mif user_input := st.chat_input("Ask about local ordinances and resolutions:"):[m
     with st.chat_message("user"):[m
         st.markdown(user_input)[m
 [m
[32m+[m[32m    # Clean chat history before sending to backend[m
[32m+[m[32m    history = [[m
[32m+[m[32m        {"role": msg["role"], "content": msg["content"]}[m
[32m+[m[32m        for msg in st.session_state.messages[m
[32m+[m[32m    ][m
[32m+[m
     # Backend API call[m
     response = requests.post([m
[31m-        'http://127.0.0.1:8000/api/chat/',[m
[31m-        json={"message": user_input, "history": st.session_state.messages}[m
[32m+[m[32m        f'http://{backend_url}:8000/api/chat/',[m
[32m+[m[32m        json={"message": user_input, "history": history}[m
     )[m
 [m
     if response.status_code == 200:[m
[1mdiff --git a/generate.py b/generate.py[m
[1mindex d7e5d16..b3b9b15 100644[m
[1m--- a/generate.py[m
[1m+++ b/generate.py[m
[36m@@ -5,6 +5,6 @@[m [mtokenizer = AutoTokenizer.from_pretrained("BAAI/bge-base-en-v1.5")[m
 model = AutoModel.from_pretrained("BAAI/bge-base-en-v1.5")[m
 [m
 # Save them to a local directory (e.g., './bge-base-en-v1.5')[m
[31m-save_path = "embedding"[m
[32m+[m[32msave_path = "embeddings"[m
 tokenizer.save_pretrained(save_path)[m
 model.save_pretrained(save_path)[m
[1mdiff --git a/requirements.txt b/requirements.txt[m
[1mindex d3b26e3..48787ab 100644[m
[1m--- a/requirements.txt[m
[1m+++ b/requirements.txt[m
[36m@@ -1,7 +1,12 @@[m
 boto3==1.38.5[m
 Django==5.2.1[m
[32m+[m[32mdjango-cors-headers==4.7.0[m
[32m+[m[32mdjangorestframework==3.16.0[m
[32m+[m[32mgunicorn==23.0.0[m
 openai==1.78.1[m
 pandas==2.2.3[m
 Requests==2.32.3[m
 transformers==4.48.1[m
[31m-weaviate_client==4.11.3[m
[32m+[m[32mweaviate-client==4.11.3[m
[32m+[m[32mpython-dotenv==1.1.0[m
[32m+[m[32mnumpy==1.26.4[m
